# 几个常见的并发容器
- ConcurrentHashMap : 线程安全的 HashMap
- CopyOnWriteArrayList : 线程安全的 List，在读多写少的场合性能非常好，远远好于 Vector。
- ConcurrentLinkedQueue : 高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列。
- BlockingQueue : 这是一个接口，JDK 内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。
- ConcurrentSkipListMap : 跳表的实现。这是一个 Map，使用跳表的数据结构进行快速查找。
---
## 1. ConcurrentHashMap
我们知道 HashMap 不是线程安全的，在并发场景下如果要保证一种可行的方式是使用 Collections.synchronizedMap() 方法来包装我们的 HashMap。但这是通过使用一个全局的锁来同步不同线程间的并发访问，因此会带来不可忽视的性能问题。

所以就有了 HashMap 的线程安全版本——ConcurrentHashMap 的诞生。

在 ConcurrentHashMap 中,无论是读操作还是写操作都能保证很高的性能：在进行读操作时(几乎)不需要加锁，而在写操作时通过锁分段技术只对所操作的段加锁而不影响客户端对其它段的访问。

---
## 2. CopyOnWriteArrayList
为了将读取的性能发挥到极致，CopyOnWriteArrayList 读取是完全不用加锁的，并且更厉害的是：写入也不会阻塞读取操作。只有写入和写入之间需要进行同步等待。这样一来，读操作的性能就会大幅度提升。那它是怎么做的呢？

CopyOnWriteArrayList 类的所有可变操作（add，set 等等）都是通过创建底层数组的新副本来实现的。当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。

CopyOnWriteArrayList 写入操作 add()方法在添加集合的时候加了锁，保证了同步，避免了多线程写的时候会 copy 出多个副本出来。

---
## 3. ConcurrentLinkedQueue
Java 提供的线程安全的 Queue 可以分为阻塞队列和非阻塞队列，其中阻塞队列的典型例子是 BlockingQueue，非阻塞队列的典型例子是 ConcurrentLinkedQueue，在实际应用中要根据实际需要选用阻塞队列或者非阻塞队列。 

**阻塞队列通过加锁来实现，非阻塞队列通过 CAS 操作实现。**

从名字可以看出，ConcurrentLinkedQueue这个队列使用链表作为其数据结构．ConcurrentLinkedQueue 应该算是在高并发环境中性能最好的队列了。它之所有能有很好的性能，是因为其内部复杂的实现。

ConcurrentLinkedQueue 适合在对性能要求相对较高，同时对队列的读写存在多个线程同时进行的场景，即如果对队列加锁的成本较高则适合使用无锁的 ConcurrentLinkedQueue 来替代。

---
## 4. BlockingQueue
阻塞队列（BlockingQueue）被广泛使用在“生产者-消费者”问题中，其原因是 BlockingQueue 提供了可阻塞的插入和移除的方法。当队列容器已满，生产者线程会被阻塞，直到队列未满；当队列容器为空时，消费者线程会被阻塞，直至队列非空时为止。
以下是三个常见的BlockingQueue 的实现类：ArrayBlockingQueue、LinkedBlockingQueue 、PriorityBlockingQueue 。

- ArrayBlockingQueue
    
    - ArrayBlockingQueue 是 BlockingQueue 接口的有界队列实现类，底层采用数组来实现。
    - ArrayBlockingQueue 一旦创建，容量不能改变。其并发控制采用可重锁 ReentrantLock ，不管是插入操作还是读取操作，都需要获取到锁才进行操作。
    - 当队列容量满时，尝试将元素放入队列将导致操作阻塞;尝试从一个空队中取一个元素也会同样阻塞。
    - ArrayBlockingQueue 默认情况下不能保证线程访问队列的公平性，所公平性是指严格按照线程等待的绝对时间顺序，即最先等待的线程能够最先问到 ArrayBlockingQueue。而非公平性则是指访问ArrayBlockingQueue 的顺序不是遵守严格的时间顺序，有可能存在，当ArrayBlockingQueue 可以被访问时，长时间阻塞的线程依然无法访问到ArrayBlockingQueue。如果保证公平性，通常会降低吞吐量。如果需要获公平性的 ArrayBlockingQueue，可采用如下代码：`private staticArrayBlockingQueue<Integer> blockingQueue = newArrayBlockingQueue<Integer>(10,true);`
- LinkedBlockingQueue

    -  LinkedBlockingQueue 底层基于单向链表实现的阻塞队列，可以当做无界队列也可以当做有界队列来使用，同样满足 FIFO 的特性，与 ArrayBlockingQueue 相比起来具有更高的吞吐量，为了防止 LinkedBlockingQueue 容量迅速增，损耗大量内存。通常在创建 LinkedBlockingQueue 对象时，会指定其大小，如果未指定，容量等于 Integer.MAX_VALUE 。
- PriorityBlockingQueue

    - PriorityBlockingQueue 是一个支持优先级的无界阻塞队列。默认情况下元素采用自然顺序进行排序，也可以通过自定义类实现 compareTo() 方法来指定元素排序规则，或者初始化时通过构造器参数 Comparator 来指定排序规则。
    - PriorityBlockingQueue 并发控制采用的是可重入锁 ReentrantLock
    - PriorityBlockingQueue 队列为无界队列（PriorityBlockingQueue 只能指定初始的队列大小，后面插入元素的时候，如果空间不够的话会自动扩容）。

---
## 5.ConcurrentSkipListMap
ConcurrentSkipListMap 使用**跳表**来实现了map

跳表的本质是同时维护了多个链表，并且链表是分层的，

跳表是一种利用空间换时间的算法。

跳表内元素是有序的

就查询的性能而言，跳表的时间复杂度是 O(logn) 

跳表是一种可以用来快速查找的数据结构，有点类似于平衡树。它们都可以对元素进行快速的查找。但一个重要的区别是：对平衡树的插入和删除往往很可能导致平衡树进行一次全局的调整。而对跳表的插入和删除只需要对整个数据结构的局部进行操作即可。这样带来的好处是：在高并发的情况下，你会需要一个全局锁来保证整个平衡树的线程安全。而对于跳表，你只需要部分锁即可。这样，在高并发环境下，你就可以拥有更好的性能。

![跳表示例](https://camo.githubusercontent.com/f4b598e582ee28e9f64ddf6d8a534b4f0ffa1bd1efd3f3544c7e9e62ed972319/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d31322d392f33323030353733382e6a7067)