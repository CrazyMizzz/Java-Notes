# 如何解决消息不丢失

1. MQ

    当消费者在完成消息的处理之前宕机了，如果保证这条消息不丢失？

    首先需要设置MQ对消息的持久化

    MQ在把消息发送给消费者以后会等待一个ack，收到ack以后才会把这个消息删除。
    
    通常MQ在发送消息到消费者手上以后就会自动ACK，我们可以取消自动ACK，在消费者成功消费以后手动的给MQ发送一个ack，这样就算没消费完就宕机了，MQ迟迟未收到ack，就会重新将这条消息发送到其他服务实例上，这样的话就可以保证消息不会因为消费者宕机而丢失。

2. Kafka

    这块比较常见的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。大家想想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊。

    生产环境也遇到过，我们也是，之前 Kafka 的 leader 机器宕机了，将 follower 切换为 leader 之后，就会发现说这个数据就丢了。

    所以此时一般是要求起码设置如下 4 个参数：

    - 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
    - 在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。
    - 在 producer 端设置 acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。
    - 在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。
    
    我们生产环境就是按照上述要求配置的，这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。